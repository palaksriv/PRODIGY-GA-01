{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OkDJUr_nZ3d"
      },
      "outputs": [],
      "source": [
        "!pip install transformers dataset accelerate torch\n",
        "from datasets import load_dataset\n",
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/palaksriv/PRODIGY-GA-01.git"
      ],
      "metadata": {
        "id": "Yqci8mTnnmsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "f2VVb-auob5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls PRODIGY-GA-01/data"
      ],
      "metadata": {
        "id": "udbzWsUCoeQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8vv-xdgpXq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset('text',data_files={ 'train':\"PRODIGY-GA-01/data/train.txt\"}) #helps in batching\n",
        "#rather than having it done manually"
      ],
      "metadata": {
        "id": "OAGn0DhdoouJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "fXMfDUQqo4cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='gpt2'\n",
        "tokenizer=GPT2Tokenizer.from_pretrained(model_name)\n",
        "model=GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer.pad_token=tokenizer.eos_token"
      ],
      "metadata": {
        "id": "n5ZeEwaDqBRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "H4_4k2iHqwhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sample):\n",
        "  return tokenizer(\n",
        "      sample['text'],\n",
        "      truncation=True,\n",
        "      padding='max_length',\n",
        "      max_length=128\n",
        "  )"
      ],
      "metadata": {
        "id": "eTYXWMvKrQgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset=dataset.map(tokenize,batched=True,remove_columns=['text'])"
      ],
      "metadata": {
        "id": "i6E6eyxurn1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "8tMf7b_2r02a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###training"
      ],
      "metadata": {
        "id": "X2FfUbb4sD9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "training_args=TrainingArguments(\n",
        "    output_dir='/results',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=2,\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        ")\n"
      ],
      "metadata": {
        "id": "4yhkLXxcuFse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")"
      ],
      "metadata": {
        "id": "uTP8cjjzxdsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    data_collator=data_collator\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "EzIvEN1Tv6qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n"
      ],
      "metadata": {
        "id": "C5LgU_402Ebv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"<|startoftext|>The night was unusually quiet\"\n",
        "input_ids=tokenizer.encode(prompt,return_tensors='pt')\n",
        "input_ids = input_ids.to(model.device) #move input_ids to the same device as the model\n",
        "attention_mask = input_ids.ne(tokenizer.pad_token_id).long()\n",
        "output=model.generate(input_ids=input_ids,attention_mask=attention_mask,max_length=150,temperature=0.8,top_p=0.95,do_sample=True,eos_token_id=tokenizer.eos_token_id,pad_token_id=tokenizer.pad_token_id)\n",
        "generated_text=tokenizer.decode(output[0],skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "yWcnmY2GxPPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('generated_story.txt','w') as f:\n",
        "  f.write(generated_text)"
      ],
      "metadata": {
        "id": "7GZwbkkQ1r44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkV-dWml2033"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}